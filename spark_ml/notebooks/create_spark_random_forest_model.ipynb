{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current spark version is 2.4.4\n"
     ]
    }
   ],
   "source": [
    "println(s\"Current spark version is ${spark.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|label| count|\n",
      "+-----+------+\n",
      "|    1|800000|\n",
      "|    0|800000|\n",
      "+-----+------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dataSchema = StructType(StructField(target,IntegerType,true), StructField(id,LongType,true), StructField(raw_timestamp,StringType,true), StructField(query_status,StringType,true), StructField(author,StringType,true), StructField(tweet,StringType,true))\n",
       "dataPath = /home/jovyan/data/training.1600000.processed.noemoticon.csv\n",
       "raw_sentiment = [label: int, tweet: string]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[label: int, tweet: string]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.types.{StructType, StructField, IntegerType, LongType, StringType}\n",
    "\n",
    "val dataSchema = new StructType()\n",
    "    .add(\"target\", IntegerType)\n",
    "    .add(\"id\", LongType)\n",
    "    .add(\"raw_timestamp\", StringType)\n",
    "    .add(\"query_status\", StringType)\n",
    "    .add(\"author\", StringType)\n",
    "    .add(\"tweet\", StringType)\n",
    "\n",
    "    \n",
    "val dataPath= \"/home/jovyan/data/training.1600000.processed.noemoticon.csv\"\n",
    "\n",
    "val raw_sentiment = spark.read\n",
    "    .format(\"csv\")\n",
    "    .option(\"header\",false)\n",
    "    .schema(dataSchema)\n",
    "    .load(dataPath)\n",
    "    .selectExpr(\"(case when target=4 then 1 else 0 end) as label\",\"tweet\")\n",
    "\n",
    "raw_sentiment.groupBy($\"label\").count.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer = tok_0a9e34b79e07\n",
       "stopWordsRemover = stopWords_4f731dd6824a\n",
       "hashingTF = hashingTF_920979ae9aba\n",
       "rf = rfc_fbc1893e4117\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "pipeline: org.apache.spark.ml.P...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "rfc_fbc1893e4117"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
    "import org.apache.spark.ml.classification.{RandomForestClassificationModel, RandomForestClassifier}\n",
    "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n",
    "import org.apache.spark.ml.feature.{IndexToString, StringIndexer, VectorIndexer}\n",
    "import org.apache.spark.ml.feature.{HashingTF, Tokenizer, StopWordsRemover}\n",
    "import org.apache.spark.ml.linalg.Vector\n",
    "import org.apache.spark.sql.Row\n",
    "\n",
    "\n",
    "// разбиватель твита на массив слов\n",
    "val tokenizer = new Tokenizer()\n",
    "    .setInputCol(\"tweet\")\n",
    "    .setOutputCol(\"words\")\n",
    "\n",
    "// удалитель незначащих слов\n",
    "val stopWordsRemover = new StopWordsRemover()\n",
    "    .setInputCol(tokenizer.getOutputCol)\n",
    "    .setOutputCol(\"cleaned_words\")\n",
    "\n",
    "// счетчик частоты слов\n",
    "val hashingTF = new HashingTF()\n",
    "    .setNumFeatures(1000)\n",
    "    .setInputCol(stopWordsRemover.getOutputCol)\n",
    "    .setOutputCol(\"features\")\n",
    "\n",
    "//val testT = tokenizer.transform(raw_sentiment)\n",
    "//testT.show()\n",
    "\n",
    "//val testWR = swRemover.transform(testT)\n",
    "//testWR.show()\n",
    "\n",
    "//val testTF = hashingTF.transform(testWR)\n",
    "\n",
    "//testTF.select($\"words\", $\"features\").show(50, 200)\n",
    "\n",
    "// классификатор RandomForest, кол-во деревьев - 3\n",
    "val rf = new RandomForestClassifier()\n",
    "  .setLabelCol(\"label\")\n",
    "  .setFeaturesCol(\"features\")\n",
    "  .setNumTrees(3)\n",
    "\n",
    "// соединяем все элементы в pipeline\n",
    "val pipeline = new Pipeline()\n",
    "  .setStages(Array(tokenizer, stopWordsRemover, hashingTF, rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model = pipeline_d732f58e5dab\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "pipeline_d732f58e5dab"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// обучаем модель\n",
    "val model = pipeline.fit(raw_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "// сохраняем модель\n",
    "model.write.overwrite().save(\"/home/jovyan/models/spark-random_forest-ml-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sameModel = pipeline_d732f58e5dab\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "pipeline_d732f58e5dab"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// загружаем модель в новый объект\n",
    "val sameModel = PipelineModel.load(\"/home/jovyan/models/spark-random_forest-ml-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+\n",
      "|prediction|  count|\n",
      "+----------+-------+\n",
      "|       0.0| 218339|\n",
      "|       1.0|1381661|\n",
      "+----------+-------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "predictionsDF = [label: int, tweet: string ... 6 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[label: int, tweet: string ... 6 more fields]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// запускаем модель\n",
    "val predictionsDF = sameModel.transform(raw_sentiment)\n",
    "\n",
    "predictionsDF.select($\"label\", $\"probability\", $\"prediction\").groupBy($\"prediction\").count.show\n",
    "//.where(\"label = 0\").show(100, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "getProbability = UserDefinedFunction(<function1>,DoubleType,Some(List(org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7)))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "UserDefinedFunction(<function1>,DoubleType,Some(List(org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7)))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "val getProbability = udf((prediction: org.apache.spark.ml.linalg.Vector) => prediction(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|  clean_probability|\n",
      "+-------------------+\n",
      "| 0.5028275172582966|\n",
      "| 0.5028275172582966|\n",
      "| 0.5028275172582966|\n",
      "| 0.5028275172582966|\n",
      "| 0.5028275172582966|\n",
      "| 0.5028275172582966|\n",
      "| 0.5028275172582966|\n",
      "| 0.5714848214956812|\n",
      "| 0.5028275172582966|\n",
      "| 0.5028275172582966|\n",
      "| 0.5028275172582966|\n",
      "| 0.5028275172582966|\n",
      "| 0.5028275172582966|\n",
      "| 0.5714848214956812|\n",
      "| 0.5028275172582966|\n",
      "|0.32599726727588957|\n",
      "| 0.5028275172582966|\n",
      "| 0.5028275172582966|\n",
      "| 0.5028275172582966|\n",
      "| 0.5028275172582966|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictionsDF.select(getProbability($\"probability\").alias(\"clean_probability\")).show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available line magics:\n",
      "%lsmagic %showtypes %showoutput %adddeps %truncation %addjar\n",
      "\n",
      "Available cell magics:\n",
      "%%sql %%html %%javascript %%dataframe %%scala\n",
      "\n",
      "Type %<magic_name> for usage info.\n",
      "         \n"
     ]
    }
   ],
   "source": [
    "%lsmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}